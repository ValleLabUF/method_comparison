---
title: "Compare Parameter Discretization with PDFs"
author: "Josh Cullen"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: 
    fig_caption: yes
    latex_engine: xelatex
header-includes:
  - \usepackage{float}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

# Background

Due to the comments and concerns we've received about the use of discretized step lengths (SL) and turning angles (TA) in our behavior estimation model, this document will determine whether our method characterizes distribution shapes not possible through the use of tpyical probability density functions (PDFs) used for SL (gamma, Weibull) and TA (von Mises, wrapped Cauchy). This is demonstrated for empirical snail kite data originally tagged at Lake Toho as well as the snow leopard data.


# Snail Kite Example

First, let's take a look at the histograms of step lengths and turning angles for the top three behaviors identified by the LDA model:
\hfill\break

```{r, message=FALSE, warning=FALSE}
#######################
#### Run LDA Model ####
#######################

set.seed(1)
setwd("~/Documents/Snail Kite Project/Data/R Scripts/ValleLabUF/git_LDA_behavior")

library('MCMCpack')
library('Rcpp')
library(progress)
library(tidyverse)
library(lubridate)
library(rnaturalearth)
library(rnaturalearthdata)
library(sf)
library(viridis)
library(circular)
library(wesanderson)

source('LDA_behavior_function.R')
source('gibbs sampler.R')
source('helper functions.R')
sourceCpp('aux1.cpp')




############################
#### Load and Prep Data ####
############################

#get data
dat<- read.csv('Snail Kite Gridded Data_TOHO_behav2.csv', header = T, sep = ',')
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)  #for later behavioral assignment

nbins<- c(5,8)  #number of bins per param (in order)
dat_red<- dat %>% dplyr::select(c(id, tseg, SL, TA))  #only keep necessary cols
obs<- get.summary.stats_behav(dat = dat_red, nbins = nbins)  #to run Gibbs sampler on


#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
nmaxclust=max(nbins) - 1  #one fewer than max number of bins used for params
ndata.types=length(nbins)

#prior
gamma1=0.1
alpha=0.1 

#####################################################
#### Run Gibbs Sampler on All IDs Simultaneously ####
#####################################################

res=LDA_behavior_gibbs(dat=obs, gamma1=gamma1, alpha=alpha,
                       ngibbs=ngibbs, nmaxclust=nmaxclust,
                       nburn=nburn, ndata.types=ndata.types)


#################################################################
#### Visualize Histograms of Movement Parameters by Behavior ####
#################################################################

behav.res<- get_behav_hist(res = res, dat_red = dat_red)
behav.res<- behav.res[behav.res$behav <=3,]  #only select the top 3 behaviors

#Plot histograms of proportion data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
  geom_bar(stat = 'identity') +
  labs(x = "\nBin", y = "Proportion\n") +
  theme_bw() +
  theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
        axis.text.x.bottom = element_text(size = 12),
        strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
  scale_fill_manual(values = viridis(n=3), guide = F) +
  facet_grid(param ~ behav, scales = "fixed")

```


## Step Length

Focusing first on SL, I will use the `optim` function to determine the best parameter values to use within a gamma or Weibull distribution and see how well these PDFs fit the distributions generated by our model. These models are each run with a set of 100 different possible combiniations of initial values for their parameters and the set of values returning the lowest mean absolute error is retained. Below is a figure demonstrating how well the gamma and Weibull distributions compare:
\hfill\break

```{r}
### SL

#Specify the mass distributions per behavior for SL
behav.res.SL<- behav.res %>% filter(param == "SL")  #select only SL hists

#define bin number and limits for step lengths
max.dist=max(dat[dat$dt == 3600,]$dist, na.rm = T)
dist.bin.lims=quantile(dat[dat$dt == 3600,]$dist, c(0,0.25,0.50,0.75,0.90), na.rm=T)
dist.bin.lims=c(dist.bin.lims, max.dist)  #5 bins


#functions for determing probs and optimization
gamma.function=function(param){
  shape1=param[1]
  rate1=param[2]
  
  bins.estim=rep(NA,(length(dist.bin.lims) - 1))
  
  for (i in 2:length(dist.bin.lims)) {
    if (i-1 == 1) {
      bins.estim[i-1]=pgamma(dist.bin.lims[i],shape=shape1,rate=rate1)
    } else {
      bins.estim[i-1]=pgamma(dist.bin.lims[i],shape=shape1,rate=rate1)-
        pgamma(dist.bin.lims[i-1],shape=shape1,rate=rate1)
    }
  }
  
  bins.estim
}

gamma.function.optim=function(param, probs){
  shape1=param[1]
  rate1=param[2]
  
  bins.estim=rep(NA,(length(dist.bin.lims) - 1))
  
  for (i in 2:length(dist.bin.lims)) {
    if (i-1 == 1) {
      bins.estim[i-1]=pgamma(dist.bin.lims[i],shape=shape1,rate=rate1)
    } else {
      bins.estim[i-1]=pgamma(dist.bin.lims[i],shape=shape1,rate=rate1)-
        pgamma(dist.bin.lims[i-1],shape=shape1,rate=rate1)
    }
  }
  
  mean(abs(probs-bins.estim))  #Mean Absolute Error
}


weibull.function=function(param){
  shape1=param[1]
  scale1=param[2]
  
  bins.estim=rep(NA,(length(dist.bin.lims) - 1))
  
  for (i in 2:length(dist.bin.lims)) {
    if (i-1 == 1) {
      bins.estim[i-1]=pweibull(dist.bin.lims[i],shape=shape1,scale=scale1)
    } else {
      bins.estim[i-1]=pweibull(dist.bin.lims[i],shape=shape1,scale=scale1)-
        pweibull(dist.bin.lims[i-1],shape=shape1,scale=scale1)
    }
  }
  
  bins.estim
}

weibull.function.optim=function(param, probs){
  shape1=param[1]
  scale1=param[2]
  
  bins.estim=rep(NA,(length(dist.bin.lims) - 1))
  
  for (i in 2:length(dist.bin.lims)) {
    if (i-1 == 1) {
      bins.estim[i-1]=pweibull(dist.bin.lims[i],shape=shape1,scale=scale1)
    } else {
      bins.estim[i-1]=pweibull(dist.bin.lims[i],shape=shape1,scale=scale1)-
        pweibull(dist.bin.lims[i-1],shape=shape1,scale=scale1)
    }
  }
  
  mean(abs(probs-bins.estim))  #Mean Absolute Error
}


#Initialize optim functions using 100 different combinations of both params for gamma and weibull

store.SL.probs<- matrix(NA, 3*3*max(behav.res.SL$bin), 4)  #3 behaviors for 3 sources of 5 bins
colnames(store.SL.probs)<- c("prop", "bin", "source", "behav")
store.SL.probs[,2]<- rep(1:max(behav.res.SL$bin), times=3*3)
store.SL.probs[,3]<- rep(rep(c("Discretized","Gamma","Weibull"), each=max(behav.res.SL$bin)), 3)
store.SL.probs[,4]<- rep(1:3, each=3*max(behav.res.SL$bin))

#initial values for gamma distrib
param1<- vector()
param1[1]<- 0.0625
for (i in 2:10) {
  param1[i]<- 2*param1[i-1]
}

param2<- vector()
param2[1]<- 0.0001
for (i in 2:10) {
  param2[i]<- 10*param2[i-1]
}

gamma.params<- expand.grid(param1, param2)


#initial values for weibull distrib
param1<- vector()
param1[1]<- 0.0625
for (i in 2:10) {
  param1[i]<- 2*param1[i-1]
}


param2<- vector()
param2[1]<- 25
for (i in 2:10) {
  param2[i]<- 2*param2[i-1]
}

weibull.params<- expand.grid(param1, param2)


for (i in 1:length(unique(behav.res$behav))) {
  behav.prop<- behav.res.SL %>% filter(behav == i) %>% dplyr::select(prop)
  
  
  SL.gamma.res<- matrix(NA, nrow(gamma.params), 3)
  colnames(SL.gamma.res)<- c("param1","param2","value")
  for (j in 1:nrow(gamma.params)) {
  SL.gamma.fit<- optim(c(gamma.params[j,1], gamma.params[j,2]), gamma.function.optim,
                       probs = behav.prop$prop, method = "Nelder-Mead")
  SL.gamma.res[j,1:2]<- SL.gamma.fit$par
  SL.gamma.res[j,3]<- SL.gamma.fit$value
  }
  
  
  SL.weibull.res<- matrix(NA, nrow(weibull.params), 3)
  colnames(SL.weibull.res)<- c("param1","param2","value")
  for (k in 1:nrow(weibull.params)) {
  SL.weibull.fit<- optim(c(weibull.params[k,1], weibull.params[k,2]), weibull.function.optim,
                         probs = behav.prop$prop, method = "Nelder-Mead")
  SL.weibull.res[k,1:2]<- SL.weibull.fit$par
  SL.weibull.res[k,3]<- SL.weibull.fit$value
  }
  
  ind<- which(store.SL.probs[,4] == i)
  store.SL.probs[ind,1]<- c(behav.prop$prop,
                            gamma.function(SL.gamma.res[which.min(SL.gamma.res[,"value"]),
                                                        c("param1","param2")]),
                            weibull.function(SL.weibull.res[which.min(SL.weibull.res[,"value"]),
                                                            c("param1","param2")]))
}

store.SL.probs<- as.data.frame(store.SL.probs)
store.SL.probs$prop<- as.numeric(as.character(store.SL.probs$prop))
store.SL.probs$behav<- factor(store.SL.probs$behav, levels = c(1:3))
levels(store.SL.probs$behav)<- c("Encamped","Exploratory","Transit")

```

```{r, fig.align='center', fig.width=6, fig.height=4, fig.pos='H', fig.cap="Comparison of step length distributions for snail kites."}
#Step Length comparison
ggplot(store.SL.probs, aes(x=bin, y=prop)) +
  geom_area(aes(fill=source, color = source, group = source),
            position = position_dodge(width = 0), stat="identity", alpha = 0.35) +
  labs(x="Bins", y="Proportion") +
  scale_fill_viridis_d() +
  scale_color_viridis_d(guide = F) +
  theme_bw() +
  facet_wrap(~behav) +
  guides(fill = guide_legend(title = "Distribution", override.aes = list(alpha = 1))) +
  theme(axis.title = element_text(size = 16), axis.text = element_text(size = 12),
        strip.text = element_text(size = 12, face = "bold"))
```
\hfill\break

Both gamma and Weibull distributions appear to fit the discretized distribution from our Bayesian model well the 'Encamped' and 'Transit' behaviors, but not as well for the 'Exploratory' behavior. In this intermediate behavior, the parametric gamma and Weibull distributions do not fit the proportion of observations well for the bins on the margin of the distribution (1,2,5), but they do fit the bins with the greatest proportions of observations well (bins 3 and 4). Now, let's see how the parametric distributions fare against the turning angle distributions generated by our model.


## Turning Angle

The same method used to determine the best parameter values for SL (based on maximum likelihood) was also used for TA.

```{r}
### TA

#Specify the mass distributions per behavior for TA
behav.res.TA<- behav.res %>% filter(param == "TA")  #select only TA hists

#define bin number and limits for turning angles
angle.bin.lims=seq(from=-pi, to=pi, by=pi/4)  #8 bins


vm.function=function(param){
  mu1=param[1]
  kappa1=exp(param[2])
  
  bins.estim=rep(NA,(length(angle.bin.lims) - 1))
  
  for (i in 2:length(angle.bin.lims)) {
    if (i-1 == 1) {
      bins.estim[i-1]=pvonmises(angle.bin.lims[i],mu=mu1,kappa=kappa1)
    } else {
      bins.estim[i-1]=pvonmises(angle.bin.lims[i],mu=mu1,kappa=kappa1)-
        pvonmises(angle.bin.lims[i-1],mu=mu1,kappa=kappa1)
    }
  }
  
  bins.estim
}

vm.function.optim=function(param, probs){
  mu1=param[1]
  kappa1=exp(param[2])
  
  bins.estim=rep(NA,(length(angle.bin.lims) - 1))
  
  for (i in 2:length(angle.bin.lims)) {
    if (i-1 == 1) {
      bins.estim[i-1]=pvonmises(angle.bin.lims[i],mu=mu1,kappa=kappa1)
    } else {
      bins.estim[i-1]=pvonmises(angle.bin.lims[i],mu=mu1,kappa=kappa1)-
        pvonmises(angle.bin.lims[i-1],mu=mu1,kappa=kappa1)
    }
  }
  
  mean(abs(probs-bins.estim))  #Mean Absolute Error
}


wc.function=function(param){
  mu1=param[1]
  rho1=exp(param[2]) / (1+exp(param[2]))
  
  bins.estim=rep(NA,(length(angle.bin.lims) - 1))
  
  for (i in 2:length(angle.bin.lims)) {
    
    pwrappedcauchy=integrate(dwrappedcauchy, angle.bin.lims[i-1], angle.bin.lims[i],
                             mu=circular(mu1), rho=rho1)
    bins.estim[i-1]=pwrappedcauchy$value
  }
  
  bins.estim
}

wc.function.optim=function(param, probs){
  mu1=param[1]
  rho1=exp(param[2]) / (1+exp(param[2]))
  
  bins.estim=rep(NA,(length(angle.bin.lims) - 1))
  
  for (i in 2:length(angle.bin.lims)) {
    
    pwrappedcauchy=integrate(dwrappedcauchy, angle.bin.lims[i-1], angle.bin.lims[i],
                             mu=circular(mu1), rho=rho1)
    bins.estim[i-1]=pwrappedcauchy$value
  }
  
  mean(abs(probs-bins.estim))  #Mean Absolute Error
}


#Initialize optim functions using 100 different combinations of both params for von mises and wrapped cauchy

store.TA.probs<- matrix(NA, 3*3*max(behav.res.TA$bin), 4)  #3 behaviors for 3 sources of 8 bins
colnames(store.TA.probs)<- c("prop", "bin", "source", "behav")
store.TA.probs[,2]<- rep(1:max(behav.res.TA$bin), times=3*3)
store.TA.probs[,3]<- rep(rep(c("Discretized","von Mises","wrapped Cauchy"),
                             each=max(behav.res.TA$bin)), 3)
store.TA.probs[,4]<- rep(1:3, each=3*max(behav.res.TA$bin))


#initial values for von mises and wrapped cauchy distribs
param1<- seq(-pi, pi, length.out = 10)
param2<- seq(0.1, 1, length.out = 10)

TA.init.params<- expand.grid(param1, param2)


for (i in 1:length(unique(behav.res$behav))) {
  behav.prop<- behav.res.TA %>% filter(behav == i) %>% dplyr::select(prop)
  
  TA.vm.res<- matrix(NA, nrow(TA.init.params), 3)
  colnames(TA.vm.res)<- c("param1","param2","value")
  for (j in 1:nrow(TA.init.params)) {
  TA.vm.fit<- optim(c(TA.init.params[j,1], TA.init.params[j,2]), vm.function.optim,
                    probs = behav.prop$prop, method = "Nelder-Mead")
  TA.vm.res[j,1:2]<- TA.vm.fit$par
  TA.vm.res[j,3]<- TA.vm.fit$value
  }
  
  TA.wc.res<- matrix(NA, nrow(TA.init.params), 3)
  colnames(TA.wc.res)<- c("param1","param2","value")
  for (k in 1:nrow(TA.init.params)) {
  TA.wc.fit<- optim(c(TA.init.params[k,1], TA.init.params[k,2]), wc.function.optim,
                    probs = behav.prop$prop, method = "Nelder-Mead")
  TA.wc.res[k,1:2]<- TA.wc.fit$par
  TA.wc.res[k,3]<- TA.wc.fit$value
  }
  
  ind<- which(store.TA.probs[,4] == i)
  store.TA.probs[ind,1]<- c(behav.prop$prop,
                            vm.function(TA.vm.res[which.min(TA.vm.res[,"value"]),
                                                     c("param1","param2")]),
                            wc.function(TA.wc.res[which.min(TA.wc.res[,"value"]),
                                                     c("param1","param2")]))
}

store.TA.probs<- as.data.frame(store.TA.probs)
store.TA.probs$prop<- as.numeric(as.character(store.TA.probs$prop))
store.TA.probs$behav<- factor(store.TA.probs$behav, levels = c(1:3))
levels(store.TA.probs$behav)<- c("Encamped","Exploratory","Transit")


```

```{r, fig.align='center', fig.width=6, fig.height=4, fig.pos='H', fig.cap="Comparison of turning angle distributions for snail kites."}
#Turning Angle comparison
ggplot(store.TA.probs, aes(x=bin, y=prop)) +
  geom_area(aes(fill=source, color = source, group = source),
            position = position_dodge(width = 0), stat="identity", alpha = 0.35) +
  labs(x="Bins", y="Proportion") +
  scale_fill_viridis_d() +
  scale_color_viridis_d(guide = F) +
  theme_bw() +
  facet_wrap(~behav) +
  guides(fill = guide_legend(title = "Distribution", override.aes = list(alpha = 1))) +
  theme(axis.title = element_text(size = 16), axis.text = element_text(size = 12),
        strip.text = element_text(size = 12, face = "bold"))
```
\hfill\break

The wrapped Cauchy distribution matched our discretized distribution relatively well for the bins with greatest proportion of observations in each of the three behaviors, but not as well for the others. This is particularly apparent for bins 2-7 of the 'Exploratory' behavior and bins 1, 2, 3, 6, 7, and 8 for the 'Transit' behavior. Although the von Mises distribution was able to somewhat fit the discretized shape of the 'Transit' behavior, it performed poorly for the 'Encamped' and 'Exploratory' behaviors. This resulted in a uniform distribution instead of a shape where most of the probability mass was in the first and last bins ($-\pi/\pi$) with a large drop in probability towards angles closer to 0 radians (bins 4 and 5). To determine if these results were driven by the shape of the peak (one single peak in the middle vs a peak at each limit), the probability masses were centered at $\pi$ rather than at zero and then reanalayzed (*not shown here*). These results showed that the 'Encamped' and 'Exploratory' behaviors were fit relatively well by the von Mises distribution, but now the 'Transit' behavior was characterized with a uniform distribution. This indicates that the von Mises distribution cannot properly fit distributions where probability mass is at the edges rather than in the middle.
\hfill\break


# Snow Leopard Example

As with the snail kite data, let's take a look at the histograms of step lengths and turning angles for the top three behaviors identified by the LDA model:
\hfill\break

```{r, message=FALSE, warning=FALSE}
#######################
#### Run LDA Model ####
#######################

set.seed(1)
setwd("~/Documents/Snail Kite Project/Data/R Scripts/ValleLabUF/git_LDA_behavior")

set.seed(1)

#get data
dat<- read.csv('Snow Leopard Data_behav.csv', header = T, sep = ',')
dat$date<- dat$date %>% as_datetime()
dat.list<- df.to.list(dat)  #for later behavioral assignment

nbins<- c(5,8)  #number of bins per param (in order)
dat_red<- dat %>% dplyr::select(c(id, tseg, SL, TA))  #only keep necessary cols
obs<- get.summary.stats_behav(dat = dat_red, nbins = nbins)  #to run Gibbs sampler on


#prepare for Gibbs sampler
ngibbs=1000
nburn=ngibbs/2
nmaxclust=max(nbins) - 1  #one fewer than max number of bins used for params
ndata.types=length(nbins)

#prior
gamma1=0.1
alpha=0.1 

#####################################################
#### Run Gibbs Sampler on All IDs Simultaneously ####
#####################################################

res=LDA_behavior_gibbs(dat=obs, gamma1=gamma1, alpha=alpha,
                       ngibbs=ngibbs, nmaxclust=nmaxclust,
                       nburn=nburn, ndata.types=ndata.types)


#################################################################
#### Visualize Histograms of Movement Parameters by Behavior ####
#################################################################

behav.res<- get_behav_hist(res = res, dat_red = dat_red)
behav.res<- behav.res[behav.res$behav <=3,]  #only select the top 3 behaviors

#Plot histograms of frequency data; order color scale from slow to fast
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
  geom_bar(stat = 'identity') +
  labs(x = "\nBin", y = "Proportion\n") +
  theme_bw() +
  theme(axis.title = element_text(size = 16), axis.text.y = element_text(size = 14),
        axis.text.x.bottom = element_text(size = 12),
        strip.text = element_text(size = 14), strip.text.x = element_text(face = "bold")) +
  scale_fill_manual(values = viridis(n=3), guide = F) +
  facet_grid(param ~ behav, scales = "free_y")
```

The first two states appear to be interpretable as 'Exploratory' and 'Resting' behaviors, respectively. The third state may or may not represent a real behavior, but it will be included since it is assigned to observations ~10% of the time on average. I will refer to this third state as 'Encamped'.

## Step Length

Focusing first on SL, I will use the `optim` function to determine the best parameter values to use within a gamma or Weibull distribution and see how well these PDFs fit the distributions generated by our model. These models are each run with a set of 100 different possible combiniations of initial values for their parameters and the set of values returning the lowest mean absolute error is retained. Below is a figure demonstrating how well the gamma and Weibull distributions compare:
\hfill\break

```{r}
### SL

#Specify the mass distributions per behavior for SL
behav.res.SL<- behav.res %>% filter(param == "SL")  #select only SL hists

#define bin number and limits for step lengths
max.dist=max(dat[dat$dt == 10800,]$dist, na.rm = T)
dist.bin.lims=quantile(dat[dat$dt == 10800,]$dist, c(0,0.25,0.50,0.75,0.90), na.rm=T)
dist.bin.lims=c(dist.bin.lims, max.dist)  #5 bins



#Initialize optim functions using 100 different combinations of both params for gamma and weibull

store.SL.probs<- matrix(NA, 3*3*max(behav.res.SL$bin), 4)  #3 behaviors for 3 sources of 5 bins
colnames(store.SL.probs)<- c("prop", "bin", "source", "behav")
store.SL.probs[,2]<- rep(1:max(behav.res.SL$bin), times=3*3)
store.SL.probs[,3]<- rep(rep(c("Discretized","Gamma","Weibull"), each=max(behav.res.SL$bin)), 3)
store.SL.probs[,4]<- rep(1:3, each=3*max(behav.res.SL$bin))

#initial values for gamma distrib
param1<- vector()
param1[1]<- 0.0625
for (i in 2:10) {
  param1[i]<- 2*param1[i-1]
}

param2<- vector()
param2[1]<- 0.0001
for (i in 2:10) {
  param2[i]<- 10*param2[i-1]
}

gamma.params<- expand.grid(param1, param2)


#initial values for weibull distrib
param1<- vector()
param1[1]<- 0.25
for (i in 2:10) {
  param1[i]<- 2*param1[i-1]
}


param2<- vector()
param2[1]<- 0.0625
for (i in 2:10) {
  param2[i]<- 2*param2[i-1]
}

weibull.params<- expand.grid(param1, param2)


for (i in 1:length(unique(behav.res$behav))) {
  behav.prop<- behav.res.SL %>% filter(behav == i) %>% dplyr::select(prop)
  
  
  SL.gamma.res<- matrix(NA, nrow(gamma.params), 3)
  colnames(SL.gamma.res)<- c("param1","param2","value")
  for (j in 1:nrow(gamma.params)) {
    SL.gamma.fit<- optim(c(gamma.params[j,1], gamma.params[j,2]), gamma.function.optim,
                         probs = behav.prop$prop, method = "Nelder-Mead")
    SL.gamma.res[j,1:2]<- SL.gamma.fit$par
    SL.gamma.res[j,3]<- SL.gamma.fit$value
  }
  
  
  SL.weibull.res<- matrix(NA, nrow(weibull.params), 3)
  colnames(SL.weibull.res)<- c("param1","param2","value")
  for (k in 1:nrow(weibull.params)) {
    SL.weibull.fit<- optim(c(weibull.params[k,1], weibull.params[k,2]), weibull.function.optim,
                           probs = behav.prop$prop, method = "Nelder-Mead")
    SL.weibull.res[k,1:2]<- SL.weibull.fit$par
    SL.weibull.res[k,3]<- SL.weibull.fit$value
  }
  
  ind<- which(store.SL.probs[,4] == i)
  store.SL.probs[ind,1]<- c(behav.prop$prop,
                            gamma.function(SL.gamma.res[which.min(SL.gamma.res[,"value"]),
                                                        c("param1","param2")]),
                            weibull.function(SL.weibull.res[which.min(SL.weibull.res[,"value"]),
                                                            c("param1","param2")]))
}

store.SL.probs<- as.data.frame(store.SL.probs)
store.SL.probs$prop<- as.numeric(as.character(store.SL.probs$prop))
store.SL.probs$behav<- factor(store.SL.probs$behav, levels = c(2,3,1))
levels(store.SL.probs$behav)<- c("Resting","Encamped","Exploratory")

```

```{r, fig.align='center', fig.width=6, fig.height=4, fig.pos='H', fig.cap="Comparison of step length distributions for snow leopards."}
#Step Length comparison
ggplot(store.SL.probs, aes(x=bin, y=prop)) +
  geom_area(aes(fill=source, color = source, group = source),
            position = position_dodge(width = 0), stat="identity", alpha = 0.35) +
  labs(x="Bins", y="Proportion") +
  scale_fill_viridis_d() +
  scale_color_viridis_d(guide = F) +
  theme_bw() +
  facet_wrap(~behav) +
  guides(fill = guide_legend(title = "Distribution", override.aes = list(alpha = 1))) +
  theme(axis.title = element_text(size = 16), axis.text = element_text(size = 12),
        strip.text = element_text(size = 12, face = "bold"))
```
\hfill\break

The gamma and Weibull both fit the discretized distributions well for the 'Resting' and 'Encamped' behaviors, but had more difficulty with the 'Exploratory' behavior. The parametric distributions had particular trouble matching the mass density found in bins 1 and 3 of the 'Transit' behavior. Now, let's see how the parametric distributions fare against the turning angle distributions generated by our model.


## Turning Angle

The same method used to determine the best parameter values for SL (based on maximum likelihood) was also used for TA.

```{r}
### TA

#Specify the mass distributions per behavior for TA
behav.res.TA<- behav.res %>% filter(param == "TA")  #select only TA hists


#Initialize optim functions using 100 different combinations of both params for von mises and wrapped cauchy

store.TA.probs<- matrix(NA, 3*3*max(behav.res.TA$bin), 4)  #3 behaviors for 3 sources of 8 bins
colnames(store.TA.probs)<- c("prop", "bin", "source", "behav")
store.TA.probs[,2]<- rep(1:max(behav.res.TA$bin), times=3*3)
store.TA.probs[,3]<- rep(rep(c("Discretized","von Mises","wrapped Cauchy"),
                             each=max(behav.res.TA$bin)), 3)
store.TA.probs[,4]<- rep(1:3, each=3*max(behav.res.TA$bin))


#initial values for von mises and wrapped cauchy distribs
param1<- seq(-pi, pi, length.out = 10)
param2<- seq(0.1, 1, length.out = 10)

TA.init.params<- expand.grid(param1, param2)


for (i in 1:length(unique(behav.res$behav))) {
  behav.prop<- behav.res.TA %>% filter(behav == i) %>% dplyr::select(prop)
  
  TA.vm.res<- matrix(NA, nrow(TA.init.params), 3)
  colnames(TA.vm.res)<- c("param1","param2","value")
  for (j in 1:nrow(TA.init.params)) {
    TA.vm.fit<- optim(c(TA.init.params[j,1], TA.init.params[j,2]), vm.function.optim,
                      probs = behav.prop$prop, method = "Nelder-Mead")
    TA.vm.res[j,1:2]<- TA.vm.fit$par
    TA.vm.res[j,3]<- TA.vm.fit$value
  }
  
  TA.wc.res<- matrix(NA, nrow(TA.init.params), 3)
  colnames(TA.wc.res)<- c("param1","param2","value")
  for (k in 1:nrow(TA.init.params)) {
    TA.wc.fit<- optim(c(TA.init.params[k,1], TA.init.params[k,2]), wc.function.optim,
                      probs = behav.prop$prop, method = "Nelder-Mead")
    TA.wc.res[k,1:2]<- TA.wc.fit$par
    TA.wc.res[k,3]<- TA.wc.fit$value
  }
  
  ind<- which(store.TA.probs[,4] == i)
  store.TA.probs[ind,1]<- c(behav.prop$prop,
                            vm.function(TA.vm.res[which.min(TA.vm.res[,"value"]),
                                                  c("param1","param2")]),
                            wc.function(TA.wc.res[which.min(TA.wc.res[,"value"]),
                                                  c("param1","param2")]))
}

store.TA.probs<- as.data.frame(store.TA.probs)
store.TA.probs$prop<- as.numeric(as.character(store.TA.probs$prop))
store.TA.probs$behav<- factor(store.TA.probs$behav, levels = c(2,3,1))
levels(store.TA.probs$behav)<- c("Resting","Encamped","Exploratory")
```

```{r, fig.align='center', fig.width=6, fig.height=4, fig.pos='H', fig.cap="Comparison of turning angle distributions for snow leopards."}
#Turning Angle comparison
ggplot(store.TA.probs, aes(x=bin, y=prop)) +
  geom_area(aes(fill=source, color = source, group = source),
            position = position_dodge(width = 0), stat="identity", alpha = 0.35) +
  labs(x="Bins", y="Proportion") +
  scale_fill_viridis_d() +
  scale_color_viridis_d(guide = F) +
  theme_bw() +
  facet_wrap(~behav) +
  guides(fill = guide_legend(title = "Distribution", override.aes = list(alpha = 1))) +
  theme(axis.title = element_text(size = 16), axis.text = element_text(size = 12),
        strip.text = element_text(size = 12, face = "bold"))
```
\hfill\break

The wrapped Cauchy distribution fits turning angles for the 'Exploratory' behavior relatively well, but does not closely match the distributions of the 'Resting' or 'Encamped' behaviors. Similar to the results for the snail kite dataset, the von Mises distribution does a decent job of matching the 'Transit' behavior, but cannot fit the 'Resting' or 'Encamped' distributions well and produces uniform distributions.


# Conclusions

Based on the comparisons of distributions for the step lengths and turning angles of both snail kite and snow leopard datasets, success in using parametric PDFs to match the discretized distributions from our model was highly variable. For SL, it appears that both the gamma and Weibull were successful in matching the distributions generated from our discretized SL movement parameters for extreme states (highly left- or right-skewed), but not as well with a more intermediate distribution. For turning angles, only the wrapped Cauchy distribution was able to match the TA distributions generated from our model relatively well for all three behaviors. However, the wrapped Cauchy could not perfectly match all of the distributions. Therefore, it appears that our model may exhibit more flexibility in characterizing the distributions of step lengths and turning angles after discretization than existing methods that rely on parametric PDFs.